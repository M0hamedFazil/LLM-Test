"sql_query","pyspark_query"
"SELECT * FROM employees","df = spark.table('employees')"
"SELECT id, name FROM employees WHERE department = 'HR'","df.filter(df.department == 'HR').select('id', 'name')"
"INSERT INTO employees (id, name, department) VALUES (201, 'Alice', 'Finance')","df = spark.createDataFrame([(201, 'Alice', 'Finance')], ['id', 'name', 'department']); df.write.saveAsTable('employees', mode='append')"
"UPDATE employees SET salary = salary + 5000 WHERE department = 'IT'","df = spark.table('employees'); df.withColumn('salary', df.salary + 5000).where(df.department == 'IT').write.saveAsTable('employees', mode='append')"
"DELETE FROM employees WHERE id = 201","df = spark.table('employees'); df.filter(df.id != 201).write.saveAsTable('employees', mode='overwrite')"
"SELECT COUNT(*) FROM employees","df = spark.table('employees'); df.count()"
"SELECT department, AVG(salary) FROM employees GROUP BY department","df = spark.table('employees'); df.groupBy('department').avg('salary')"
"SELECT * FROM employees ORDER BY salary DESC","df = spark.table('employees'); df.orderBy(df.salary.desc())"
"SELECT DISTINCT department FROM employees","df = spark.table('employees'); df.select('department').distinct()"
"SELECT id, name FROM employees WHERE salary BETWEEN 40000 AND 60000","df = spark.table('employees'); df.filter((df.salary >= 40000) & (df.salary <= 60000)).select('id', 'name')"
"SELECT * FROM employees WHERE name LIKE 'A%'","df = spark.table('employees'); df.filter(df.name.startswith('A'))"
"SELECT * FROM employees WHERE department IN ('HR', 'Finance')","df = spark.table('employees'); df.filter(df.department.isin(['HR', 'Finance']))"
"SELECT MAX(salary) FROM employees","df = spark.table('employees'); df.agg({'salary': 'max'})"
"SELECT MIN(salary) FROM employees","df = spark.table('employees'); df.agg({'salary': 'min'})"
"SELECT id, name FROM employees LIMIT 5","df = spark.table('employees'); df.select('id', 'name').limit(5)"
"SELECT e.id, e.name, d.name FROM employees e JOIN departments d ON e.department = d.id","df1 = spark.table('employees'); df2 = spark.table('departments'); df1.join(df2, df1.department == df2.id).select('id', 'name', 'name')"
"SELECT department, MAX(salary) FROM employees GROUP BY department","df = spark.table('employees'); df.groupBy('department').max('salary')"
"ALTER TABLE employees ADD COLUMN hire_date DATE","df = spark.table('employees'); df.withColumn('hire_date', lit(None).cast('date'))"